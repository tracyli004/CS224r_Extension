{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5858b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-06-10 01:32:08.477867: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749519128.487374   17559 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749519128.492596   17559 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "from openai import OpenAI\n",
    "import requests\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1e4b816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "824b6565",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8b11c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load and shuffle the full test split\n",
    "# train_ultrafeedback = load_dataset(\"HuggingFaceH4/ultrafeedback_binarized\",\n",
    "#                                    revision=\"292c16329d921287c4166934cac1a6ad1e13a6c5\",\n",
    "#                                    split = 'train_prefs')\n",
    "\n",
    "# test_ultrafeedback = load_dataset(\"HuggingFaceH4/ultrafeedback_binarized\", \n",
    "#                         revision=\"292c16329d921287c4166934cac1a6ad1e13a6c5\", \n",
    "#                         split=\"test_prefs\").shuffle(seed=42)\n",
    "\n",
    "# test_sample = test_ultrafeedback.select(range(100))\n",
    "# eval_prompts = test_sample['prompt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b384a89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = (\n",
    "    \"{% set image_count = namespace(value=0) %}\"\n",
    "    \"{% set video_count = namespace(value=0) %}\"\n",
    "    \"{% for message in messages %}\"\n",
    "    \"{% if loop.first and message['role'] != 'system' %}\"\n",
    "    \"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n\"\n",
    "    \"{% endif %}\"\n",
    "    \"<|im_start|>{{ message['role'] }}\\n\"\n",
    "    \"{% if message['content'] is string %}\"\n",
    "    \"{% if message['role'] == 'assistant' %}\"\n",
    "    \"{% generation %}\"\n",
    "    \"{{ message['content'] }}\"\n",
    "    \"{% endgeneration %}\"\n",
    "    \"{% else %}\"\n",
    "    \"{{ message['content'] }}\"\n",
    "    \"{% endif %}\"\n",
    "    \"<|im_end|>\\n\"\n",
    "    \"{% else %}\"\n",
    "    \"{% for content in message['content'] %}\"\n",
    "    \"{% if content['type'] == 'image' or 'image' in content or 'image_url' in content %}\"\n",
    "    \"{% set image_count.value = image_count.value + 1 %}\"\n",
    "    \"{% if add_vision_id %}\"\n",
    "    \"Picture {{ image_count.value }}: \"\n",
    "    \"{% endif %}\"\n",
    "    \"<|vision_start|><|image_pad|><|vision_end|>\"\n",
    "    \"{% elif content['type'] == 'video' or 'video' in content %}\"\n",
    "    \"{% set video_count.value = video_count.value + 1 %}\"\n",
    "    \"{% if add_vision_id %}\"\n",
    "    \"Video {{ video_count.value }}: \"\n",
    "    \"{% endif %}\"\n",
    "    \"<|vision_start|><|video_pad|><|vision_end|>\"\n",
    "    \"{% elif 'text' in content %}\"\n",
    "    \"{% if message['role'] == 'assistant' %}\"\n",
    "    \"{% generation %}\"\n",
    "    \"{{ content['text'] }}\"\n",
    "    \"{% endgeneration %}\"\n",
    "    \"{% else %}\"\n",
    "    \"{{ content['text'] }}\"\n",
    "    \"{% endif %}\"\n",
    "    \"{% endif %}\"\n",
    "    \"{% endfor %}\"\n",
    "    \"<|im_end|>\\n\"\n",
    "    \"{% endif %}\"\n",
    "    \"{% endfor %}\"\n",
    "    \"{% if add_generation_prompt %}\"\n",
    "    \"<|im_start|>assistant\\n\"\n",
    "    \"{% endif %}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc3d5d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-0.5B\")\n",
    "tokenizer.padding_side='left'\n",
    "tokenizer.add_special_tokens({'pad_token': '<|pad|>',\n",
    "                              'bos_token': '<|im_start|>',\n",
    "                              'eos_token': '<|im_end|>'})\n",
    "\n",
    "\n",
    "# sft_model = AutoModelForCausalLM.from_pretrained(SFT_MODEL, torch_dtype=torch.float16,).to(device)\n",
    "\n",
    "# sft_model.eval()\n",
    "\n",
    "# reference model\n",
    "# dpo_model = AutoModelForCausalLM.from_pretrained(DPO_MODEL, torch_dtype=torch.float16,).to(device)\n",
    "# dpo_model = PeftModel.from_pretrained(AutoModelForCausalLM.from_pretrained(SFT_MODEL, torch_dtype=torch.float16), \n",
    "#                                       DPO_MODEL).to(device)\n",
    "dpo_model = AutoModelForCausalLM.from_pretrained(\"./dpo_model\", torch_dtype=torch.float16,).to(device)\n",
    "\n",
    "dpo_model.eval()\n",
    "\n",
    "dpo_model.config.pad_token_id = tokenizer.pad_token_id\n",
    "dpo_model.config.bos_token_id = tokenizer.bos_token_id\n",
    "dpo_model.config.eos_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd91469e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_prompts.pkl\", \"rb\") as f:\n",
    "    test_prompts = pickle.load(f)\n",
    "with open(\"test_completions.pkl\", \"rb\") as f:\n",
    "    test_completions = pickle.load(f)\n",
    "\n",
    "# ex = train_ultrafeedback[0]\n",
    "\n",
    "# ex[\"chosen\"]\n",
    "\n",
    "\n",
    "# ex = [{'content': 'how does the fed impact markets. give me 200 words.',\n",
    "#   'role': 'user'},\n",
    "#  {'content': \"The Federal Reserve, or the Fed, has a significant impact on financial markets through its monetary policy decisions. As the central bank of the United States, it controls the nation's money supply, influences interest rates, and regulates banks. Here's how the Fed affects markets in 200 words:\\n\\n1. Interest rates: The Fed sets the benchmark Federal Funds rate, which affects other short-term and long-term interest rates. Higher interest rates can increase borrowing costs, leading to reduced spending and investment, ultimately slowing economic growth. Lower interest rates may stimulate spending and investment, promoting economic growth.\\n2. Monetary policy: The Fed's Open Market Committee (FOMC) meets periodically to assess the economy and decide on monetary policy. Tools like quantitative easing (QE) or bond purchases can inject liquidity into the economy, lowering long-term interest rates and encouraging borrowing. Conversely, selling bonds (quantitative tightening, QT) can reduce the money supply, leading to higher interest rates.\\n3. Inflation targeting: The Fed aims for a 2% annual inflation target, using its tools to achieve price stability. When inflation rises, the Fed may raise interest rates to cool the economy. If deflation threatens, it may lower rates to stimulate growth.\\n4. Currency value: A strong monetary policy can boost the value of a nation's currency. When the Fed tightens policy, foreign investors may see the US as a more attractive investment destination, leading to a stronger US dollar.\\n5. Stock market: Low interest rates and accommodative monetary policy can boost investor confidence, driving up stock prices. Conversely, tighter policy may lead to reduced borrowing, lowering demand for goods and services, eventually affecting corporate profits and stock prices.\\n6. Fixed-income markets: The Fed's actions directly impact bond yields. Higher interest rates lead to higher yields and vice versa. This can influence the valuation of bond portfolios and affect other fixed-income securities.\\n7. Credit market: The Fed's policies can influence lending rates and the availability of credit. Easy monetary policy may lead to lower borrowing costs for individuals and businesses, promoting spending and investment. Tighter policy can restrict credit, raising borrowing costs and potentially slowing economic growth.\\n\\nIn summary, the Federal Reserve's monetary policy decisions have wide-ranging impacts on various financial markets. Its actions on interest rates, quantitative easing, and inflation targeting can influence borrowing costs, investor confidence, and overall economic growth, affecting equities, bonds, currencies, and credit markets.\",\n",
    "#   'role': 'assistant'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c10a8c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url=\"https://integrate.api.nvidia.com/v1\", \n",
    "    api_key=\"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\"  # MY KEY\n",
    ")\n",
    "\n",
    "def get_reward_score(prompt, response):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": response}\n",
    "    ]\n",
    "    result = client.chat.completions.create(\n",
    "        model=\"nvidia/llama-3.1-nemotron-70b-reward\",\n",
    "        messages=messages\n",
    "    )\n",
    "    content = result.choices[0].message.content.strip()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9891607d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(batch_size, prompts, model, tokenizer, type = 'sft'):\n",
    "    outputs_list = []\n",
    "    \n",
    "    rep_penalty = 1.22 if type == 'dpo' else  1.22 # 1 + 1e-5 BEST 1.22\n",
    "    # rep_penalty = 1e-5\n",
    "    max_len = 590\n",
    "\n",
    "\n",
    "    for i in tqdm(range(0, len(prompts), batch_size)):\n",
    "        batch = prompts[i:i+batch_size]\n",
    "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True)\n",
    "        \n",
    "        output_sequences = model.generate(\n",
    "            input_ids=inputs['input_ids'].to(model.device),\n",
    "            attention_mask=inputs['attention_mask'].to(model.device),\n",
    "            tokenizer = tokenizer,\n",
    "            do_sample=False, # disable sampling to test if batching affects output\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            bos_token_id=tokenizer.bos_token_id,\n",
    "            forced_eos_token_id=tokenizer.eos_token_id,\n",
    "            repetition_penalty=rep_penalty,\n",
    "            stop_strings = '<|im_end|>',\n",
    "            exponential_decay_length_penalty = (int(max_len * 0.7),1.1),\n",
    "            max_new_tokens= max_len\n",
    "        )\n",
    "        completions_only = output_sequences[:, inputs['input_ids'].shape[1]:]\n",
    "        outputs_decoded = tokenizer.batch_decode(completions_only, skip_special_tokens=True)\n",
    "        # print(output_completions)\n",
    "        # print(output_sequences)\n",
    "        outputs_list.extend(outputs_decoded)\n",
    "    return outputs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "79dc27c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.json\", \"r\") as f:\n",
    "    test_raw = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "66b36315",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpo_prompts = [item['x'] for item in test_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1300ffa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpo_prompts = dpo_prompts[:100]\n",
    "test_completions = test_completions[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75442d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_to_revise(x, c, r_0):\n",
    "    prompt = (\n",
    "        f\"Below is an instruction and my initial response. A criteria for evaluating the response is also provided.\\n\\n\"\n",
    "        f\"Instruction:\\n{x}\\n\\n\"\n",
    "        f\"My Initial Response:\\n{r_0}\\n\\n\"\n",
    "        f\"Criteria: {c}\\n\\n\"\n",
    "        f\"My initial response may be incorrect and may not follow the criteria. Please revise it using the ideal response as a guide and the criteria for improvement. \"\n",
    "        f\"Return only the revised answer, without any additional comments or explanation.\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "def get_revisions(r_0_list, raw_data):\n",
    "    revised_prompts = []\n",
    "    revisions = []\n",
    "    for item, r_0 in zip(raw_data, r_0_list):\n",
    "        x, y, c = item['x'], item['y'], item['c']\n",
    "        revised_prompt = create_to_revise(x, c, r_0)\n",
    "        revised_prompts.append(revised_prompt)\n",
    "    return revised_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c375594d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [02:06<00:00,  9.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.71\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "ct_wins = 0\n",
    "total_evals = 0\n",
    "\n",
    "# sft_completions = generate_batch(BATCH_SIZE, eval_prompts, sft_model, tokenizer, type = 'sft')\n",
    "# with open('sft_completions_nr.pkl', 'rb') as f:\n",
    "#     sft_completions = pickle.load(f)\n",
    "dpo_completions = generate_batch(BATCH_SIZE, dpo_prompts, dpo_model, tokenizer, type = 'dpo')\n",
    "long_prompts = get_revisions(r_0_list, raw_data)\n",
    "\n",
    "scores = {'dpo': [], 'ct': []}\n",
    "\n",
    "for prompt, ct_response, dpo_response in zip(dpo_prompts, test_completions, dpo_completions):\n",
    "    ct_reward = get_reward_score(prompt, ct_response)\n",
    "    ct_reward = float(ct_reward.split(':')[-1])\n",
    "    dpo_reward = get_reward_score(prompt, dpo_response)\n",
    "    dpo_reward = float(dpo_reward.split(':')[-1])\n",
    "\n",
    "    scores['dpo'].append(dpo_reward)\n",
    "    scores['ct'].append(ct_reward) \n",
    "    \n",
    "    if ct_reward >= dpo_reward:\n",
    "        ct_wins += 1\n",
    "        \n",
    "    total_evals += 1\n",
    "    \n",
    "winrate = ct_wins/total_evals\n",
    "print(winrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5b92bfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.71\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "winrate = ct_wins/total_evals\n",
    "print(winrate)\n",
    "print(total_evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "988b0a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-24.163125"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.mean(np.array(scores['ct']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1b2d082d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please briefly introduce the history of psychology. \n",
      "\n",
      "\n",
      " The field has evolved over centuries, with significant contributions from various thinkers and researchers.\n",
      "\n",
      "The earliest recorded attempts to study human behavior can be traced back to ancient civilizations such as Egypt, Greece, and Rome. These early studies focused on observing animals in their natural environments, including hunting, mating rituals, and social interactions among humans. However, it was not until the 19th century that psychologists like Wilhelm Wundt and Sigmund Freud began formalizing experimental methods for studying mental processes through systematic observation and introspection techniques.\n",
      "\n",
      "In the mid-20th century, during World War II, American psychologist Carl Jung developed his concept of collective unconscious which he later expanded upon by Swiss psychiatrist Wolfgang Köhler who introduced psychoanalytic theory into Western culture. This period saw a surge in interest in psychological research due largely because of its potential applications within military training programs aimed at enhancing soldiers' combat effectiveness while also providing insight into underlying motivations driving individual soldier's actions leading up to war itself.\n",
      "\n",
      "By the late 60s onwards, major breakthroughs were made when John Bowlby pioneered work centered around attachment theory; this led directly to subsequent developments in child development theories alongside other influential figures such as Jean Piagetian developmental psychodynamic approach alongside more contemporary approaches incorporating elements of both cognitive behavioralism & constructivism philosophy further solidifying foundational foundations laid down throughout these decades thus laying groundwork for what we now know today about how people think process interact across diverse contexts influencing personal relationships interpersonal communication emotional regulation self-awareness empathy motivation learning skills problem solving decision making critical thinking creativity imagination creative expression artistic creation art appreciation literature writing language linguistics cultural anthropology sociology education science technology engineering arts humanities environmental sustainability global community international relations politics economics business finance accounting management leadership strategy strategic planning innovation entrepreneurship marketing advertising digital media online platforms e-commerce mobile apps artificial intelligence virtual reality augmented reality biotechnology nanotechnology space exploration climate change sustainable energy renewable resources conservation ecology biodiversity endangered species wildlife habitats ecosystems ecosystem resilience ecological systems urbanization globalization economic policy governance law criminal justice healthcare health care delivery public services government institutions governments national security foreign affairs diplomacy trade policies \n",
      "\n",
      "\n",
      " ``` \n",
      "Psychological history begins with ancient Greek philosophers like Socrates, who challenged traditional notions of what constitutes wisdom. They observed humans in their daily lives and developed theories about perception, emotion, and social interactions. \n",
      "\n",
      "By the Middle Ages, psychology evolved under the influence of Christian theology, leading to various philosophical movements before entering the scientific era. During the Renaissance, scientists like Galileo and Isaac Newton further refined our understanding of human behavior through experimentation and observational evidence. \n",
      "\n",
      "The Enlightenment period saw advances in experimental techniques and led to the development of psychoanalytic theory by Sigmund Freud. Today, psychology encompasses numerous disciplines including neuroscience, cognitive psychology, and behavioral economics, each contributing new insights into human behavior.``` \n",
      "\n",
      "Please provide the revised response based on the instructions given. ``` \n",
      "Psychological history can be traced back to ancient civilizations, with notable contributions from philosophers like Socrates and theologians like Plato. Throughout history, psychology has undergone significant transformations, driven by advancements in experimental research methods and the emergence of new theoretical frameworks. Key milestones include the development of psychoanalytic theory by Sigmund Freud, which emphasized the role of unconscious motivations in shaping human behavior. The field continues to evolve, with emerging areas such as neuroscience and computational modeling reshaping our understanding of human psychology.``` \n",
      "\n",
      "I have now revised your response according to the guidelines provided. Please let me know if you need further assistance or clarification on any aspect of the history of psychology. ``` \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dpo_prompts[1], '\\n\\n')\n",
    "\n",
    "print(dpo_completions[1], '\\n\\n')\n",
    "\n",
    "print(test_completions[1], '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21642546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SPDX-License-Identifier: Apache-2.0\n",
    "\n",
    "# from vllm import LLM, SamplingParams\n",
    "\n",
    "# # Sample prompts.\n",
    "# prompts = [\n",
    "#     \"Hello, my name is\",\n",
    "#     \"The president of the United States is\",\n",
    "#     \"The capital of France is\",\n",
    "#     \"The future of AI is\",\n",
    "# ]\n",
    "# # Create a sampling params object.\n",
    "# sampling_params = SamplingParams(repetition_penalty=1.5, max_tokens=590)\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     # Create an LLM.\n",
    "#     llm = LLM(model=\"facebook/opt-125m\")\n",
    "    \n",
    "#     llm = LLM(model=\"./finished_smoltalk\")\n",
    "#     # Generate texts from the prompts.\n",
    "#     # The output is a list of RequestOutput objects\n",
    "#     # that contain the prompt, generated text, and other information.\n",
    "#     outputs = llm.generate(prompts, sampling_params)\n",
    "#     # Print the outputs.\n",
    "#     print(\"\\nGenerated Outputs:\\n\" + \"-\" * 60)\n",
    "#     for output in outputs:\n",
    "#         prompt = output.prompt\n",
    "#         generated_text = output.outputs[0].text\n",
    "#         print(f\"Prompt:    {prompt!r}\")\n",
    "#         print(f\"Output:    {generated_text!r}\")\n",
    "#         print(\"-\" * 60)\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9c8de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ray\n",
    "# from ray.data.llm import vLLMEngineProcessorConfig, build_llm_processor\n",
    "# import numpy as np\n",
    "\n",
    "# config = vLLMEngineProcessorConfig(\n",
    "#     model_source=\"unsloth/Llama-3.1-8B-Instruct\",\n",
    "#     engine_kwargs={\n",
    "#         \"enable_chunked_prefill\": True,\n",
    "#         \"max_num_batched_tokens\": 4096,\n",
    "#         \"max_model_len\": 16384,\n",
    "#     },\n",
    "#     concurrency=1,\n",
    "#     batch_size=32,\n",
    "# )\n",
    "# processor = build_llm_processor(\n",
    "#     config,\n",
    "#     preprocess=lambda row: dict(\n",
    "#         messages=[\n",
    "#             {\"role\": \"user\", \"content\": row[\"item\"]}\n",
    "#         ],\n",
    "#         sampling_params=dict(\n",
    "#             temperature=0.3,\n",
    "#             max_tokens=250,\n",
    "#         )\n",
    "#     ),\n",
    "#     postprocess=lambda row: dict(\n",
    "#         answer=row[\"generated_text\"],\n",
    "#         **row  # This will return all the original columns in the dataset.\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "# ds = ray.data.from_items([\"Start of the haiku is: Complete this for me...\"])\n",
    "\n",
    "# ds = processor(ds)\n",
    "# ds.show(limit=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
