{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "721bffa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "# from peft import PeftModel\n",
    "from openai import OpenAI\n",
    "import requests\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "# import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# from vllm import LLM, SamplingParams\n",
    "# import openai\n",
    "import time\n",
    "import tensorboard\n",
    "import pickle\n",
    "import math\n",
    "import json\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_printoptions(threshold=float('inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f799aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade \"jinja2>=3.1.0\"\n",
    "# %pip install datasets tensorboard openai tqdm\n",
    "# %pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a663972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in Prompts and Criteria and Teacher responses (Original UltraFeedback Llama responses)\n",
    "\n",
    "with open(\"train_short.json\", \"r\") as f:\n",
    "    train_short = json.load(f)\n",
    "with open(\"train_med.json\", \"r\") as f:\n",
    "    train_med = json.load(f)\n",
    "with open(\"train_long.json\", \"r\") as f:\n",
    "    train_long = json.load(f)\n",
    "with open(\"test.json\", \"r\") as f:\n",
    "    test_raw = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ed2813a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 11:34:39.905455: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749382479.931170    8438 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749382479.943862    8438 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# load tokenizer and model\n",
    "student_tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-0.5B\", padding_side='right')\n",
    "student = AutoModelForCausalLM.from_pretrained(\"./dpo_model\", torch_dtype=torch.float32)\n",
    "\n",
    "# add special tokens\n",
    "student_tokenizer.add_special_tokens({\n",
    "    'pad_token': '<|pad|>',\n",
    "    'bos_token': '<|im_start|>',\n",
    "    'eos_token': '<|im_end|>',\n",
    "})\n",
    "\n",
    "# resize model embeddings to include new tokens\n",
    "student.resize_token_embeddings(len(student_tokenizer))\n",
    "# set token ids in config\n",
    "student.config.pad_token_id = student_tokenizer.pad_token_id\n",
    "student.config.bos_token_id = student_tokenizer.bos_token_id\n",
    "student.config.eos_token_id = student_tokenizer.eos_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e36fdb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = (\n",
    "    \"{% set image_count = namespace(value=0) %}\"\n",
    "    \"{% set video_count = namespace(value=0) %}\"\n",
    "    \"{% for message in messages %}\"\n",
    "    \"{% if loop.first and message['role'] != 'system' %}\"\n",
    "    \"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n\"\n",
    "    \"{% endif %}\"\n",
    "    \"<|im_start|>{{ message['role'] }}\\n\"\n",
    "    \"{% if message['content'] is string %}\"\n",
    "    \"{% if message['role'] == 'assistant' %}\"\n",
    "    \"{% generation %}\"\n",
    "    \"{{ message['content'] }}\"\n",
    "    \"{% endgeneration %}\"\n",
    "    \"{% else %}\"\n",
    "    \"{{ message['content'] }}\"\n",
    "    \"{% endif %}\"\n",
    "    \"<|im_end|>\\n\"\n",
    "    \"{% else %}\"\n",
    "    \"{% for content in message['content'] %}\"\n",
    "    \"{% if content['type'] == 'image' or 'image' in content or 'image_url' in content %}\"\n",
    "    \"{% set image_count.value = image_count.value + 1 %}\"\n",
    "    \"{% if add_vision_id %}\"\n",
    "    \"Picture {{ image_count.value }}: \"\n",
    "    \"{% endif %}\"\n",
    "    \"<|vision_start|><|image_pad|><|vision_end|>\"\n",
    "    \"{% elif content['type'] == 'video' or 'video' in content %}\"\n",
    "    \"{% set video_count.value = video_count.value + 1 %}\"\n",
    "    \"{% if add_vision_id %}\"\n",
    "    \"Video {{ video_count.value }}: \"\n",
    "    \"{% endif %}\"\n",
    "    \"<|vision_start|><|video_pad|><|vision_end|>\"\n",
    "    \"{% elif 'text' in content %}\"\n",
    "    \"{% if message['role'] == 'assistant' %}\"\n",
    "    \"{% generation %}\"\n",
    "    \"{{ content['text'] }}\"\n",
    "    \"{% endgeneration %}\"\n",
    "    \"{% else %}\"\n",
    "    \"{{ content['text'] }}\"\n",
    "    \"{% endif %}\"\n",
    "    \"{% endif %}\"\n",
    "    \"{% endfor %}\"\n",
    "    \"<|im_end|>\\n\"\n",
    "    \"{% endif %}\"\n",
    "    \"{% endfor %}\"\n",
    "    \"{% if add_generation_prompt %}\"\n",
    "    \"<|im_start|>assistant\\n\"\n",
    "    \"{% endif %}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4c0f60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 3\n",
    "MAX_TOKENS = 512\n",
    "\n",
    "MAX_INPUT_TOKENS = 512\n",
    "ACCUM_STEPS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e969cddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLDataset(Dataset):\n",
    "    def __init__(self, dataset, tokenizer, max_length = MAX_INPUT_TOKENS):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        messages = self.dataset[idx]\n",
    "\n",
    "        new_messages = []\n",
    "        for m in messages:\n",
    "            if not new_messages and m[\"role\"] == \"user\":\n",
    "                new_messages.append(m)\n",
    "            elif new_messages and m[\"role\"] == \"assistant\":\n",
    "                new_messages.append(m)\n",
    "                break\n",
    "        if len(new_messages) != 2:\n",
    "            return self._empty_item()\n",
    "        \n",
    "        try:\n",
    "            tokenized = self.tokenizer.apply_chat_template(\n",
    "                new_messages,\n",
    "                tokenize = True,\n",
    "                max_length = self.max_length,\n",
    "                padding = 'max_length',\n",
    "                truncation = True,\n",
    "                return_dict = True,\n",
    "                return_assistant_tokens_mask=True,\n",
    "                add_generation_prompt = False,\n",
    "                chat_template = chat_template,\n",
    "                return_tensors = 'pt'\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(idx, e)\n",
    "            return self._empty_item()\n",
    "\n",
    "        input_ids = tokenized['input_ids']\n",
    "        assistant_masks = tokenized['assistant_masks']\n",
    "        if assistant_masks.sum() == 0:\n",
    "            return self._empty_item()\n",
    "\n",
    "        mod_assistant_mask = assistant_masks.clone()\n",
    "        matches = (input_ids == self.tokenizer.convert_tokens_to_ids(\"<|im_end|>\"))\n",
    "        indices = torch.nonzero(matches)\n",
    "        mod_assistant_mask[tuple(indices[-1])] = 1 # inlcude end speaking token in assistant to include in lables\n",
    "\n",
    "        attention_mask = tokenized['attention_mask']\n",
    "\n",
    "        labels = input_ids.clone()\n",
    "        labels[mod_assistant_mask == 0] = -100\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids.squeeze(0),\n",
    "            'attention_mask': attention_mask.squeeze(0),\n",
    "            'labels': labels.squeeze(0)\n",
    "        }\n",
    "    \n",
    "    def _empty_item(self):\n",
    "        return {\n",
    "            'input_ids': torch.zeros(self.max_length, dtype=torch.int32),\n",
    "            'attention_mask': torch.zeros(self.max_length, dtype=torch.int32),\n",
    "            'labels': torch.full((self.max_length,), -100, dtype=torch.int32)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94c40e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def student_generate_batch(batch_size, prompts, model, tokenizer):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-0.5B\", padding_side = 'left')\n",
    "    outputs_list = []\n",
    "\n",
    "    for i in tqdm(range(0, len(prompts), batch_size)):\n",
    "        batch = prompts[i:i+batch_size]\n",
    "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True)\n",
    "        \n",
    "        output_sequences = model.generate(\n",
    "            input_ids=inputs['input_ids'].to(model.device),\n",
    "            attention_mask=inputs['attention_mask'].to(model.device),\n",
    "            tokenizer = tokenizer,\n",
    "            do_sample=False, # disable sampling to test if batching affects output\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            bos_token_id=tokenizer.bos_token_id,\n",
    "            forced_eos_token_id=tokenizer.eos_token_id,\n",
    "            repetition_penalty=1.12,\n",
    "            stop_strings = '<|im_end|>',\n",
    "            exponential_decay_length_penalty = (int(MAX_TOKENS * 0.7),1.1),\n",
    "            max_new_tokens= MAX_TOKENS\n",
    "        )\n",
    "        completions_only = output_sequences[:, inputs['input_ids'].shape[1]:]\n",
    "        outputs_decoded = tokenizer.batch_decode(completions_only, skip_special_tokens=True)\n",
    "        # print(output_completions)\n",
    "        # print(output_sequences)\n",
    "        outputs_list.extend(outputs_decoded)\n",
    "    return outputs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04274f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "def teacher_generate_batch(prompts, model=\"gpt-4\", system_prompt=\"You are a helpful assistant.\"):\n",
    "    # Step 1: Write prompts to JSONL\n",
    "    input_path = \"batch_input.jsonl\"\n",
    "    with open(input_path, \"w\") as f:\n",
    "        for i, prompt in enumerate(prompts):\n",
    "            item = {\n",
    "                \"custom_id\": f\"request-{i}\",\n",
    "                \"method\": \"POST\",\n",
    "                \"url\": \"/v1/chat/completions\",\n",
    "                \"body\": {\n",
    "                    \"model\": model,\n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"system\", \"content\": system_prompt},\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                    ],\n",
    "                    \"max_tokens\": MAX_TOKENS,\n",
    "                    \"temperature\": 0.0,\n",
    "                    \"stop\": [\"<|im_end|>\"],\n",
    "                    \"frequency_penalty\": 1.5,\n",
    "                    \"presence_penalty\": 0.0\n",
    "                }\n",
    "            }\n",
    "            f.write(json.dumps(item) + \"\\n\")\n",
    "\n",
    "    # Step 2: Upload the file using OpenAI client\n",
    "    with open(input_path, \"rb\") as f:\n",
    "        upload = client.files.create(file=f, purpose=\"batch\")\n",
    "    file_id = upload.id\n",
    "\n",
    "    # Step 3: Submit batch\n",
    "    batch = client.batches.create(\n",
    "        input_file_id=file_id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\"\n",
    "    )\n",
    "    batch_id = batch.id\n",
    "    # print(\"Batch submitted. ID:\", batch_id)\n",
    "\n",
    "    # Step 4: Poll until complete\n",
    "    # print(\"Waiting for batch to complete...\")\n",
    "    while True:\n",
    "        batch_status = client.batches.retrieve(batch_id)\n",
    "        status = batch_status.status\n",
    "        # print(f\"Current status: {status}\")\n",
    "        if status in [\"completed\", \"failed\", \"cancelled\", \"expired\"]:\n",
    "            break\n",
    "        time.sleep(15)\n",
    "\n",
    "    if status != \"completed\":\n",
    "        raise RuntimeError(f\"Batch failed or didn't complete: {status}\")\n",
    "\n",
    "    # Step 5: Download result file\n",
    "    output_file_id = batch_status.output_file_id\n",
    "    output_response = client.files.content(output_file_id)\n",
    "    output_data = output_response.text\n",
    "\n",
    "    # Step 6: Parse results into dictionary\n",
    "    responses = {}\n",
    "    for line in output_data.splitlines():\n",
    "        obj = json.loads(line)\n",
    "        custom_id = obj[\"custom_id\"]\n",
    "        content = obj[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "        responses[custom_id] = content\n",
    "\n",
    "    # Step 7: Return outputs in order\n",
    "    return [responses[f\"request-{i}\"] for i in range(len(prompts))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d76e62eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_raw):\n",
    "    formatted_data = [[{\"content\": str(item[\"x\"]), \"role\": \"user\"},\n",
    "                       {\"content\": str(item[\"y\"]), \"role\": \"assistant\"}] for item in train_raw ]\n",
    "    return formatted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "088524b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_list(prompt, completion):\n",
    "    data = [[\n",
    "        {'content': p, 'role': 'user'},\n",
    "        {'content': c, 'role': 'assistant'}\n",
    "    ] for p, c in zip(prompt, completion)]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "072f4ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_to_revise(x, c, r_0):\n",
    "    prompt = (\n",
    "        f\"Below is an instruction and my initial response. A criteria for evaluating the response is also provided.\\n\\n\"\n",
    "        f\"Instruction:\\n{x}\\n\\n\"\n",
    "        f\"My Initial Response:\\n{r_0}\\n\\n\"\n",
    "        f\"Criteria: {c}\\n\\n\"\n",
    "        f\"My initial response may be incorrect and may not follow the criteria. Please revise it using the ideal response as a guide and the criteria for improvement. \"\n",
    "        f\"Return only the revised answer, without any additional comments or explanation.\"\n",
    "    )\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55cc206e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_revisions(r_0_list, raw_data):\n",
    "    \n",
    "    # student.eval()\n",
    "    # with torch.no_grad():\n",
    "    #     r_0_list = student_generate_batch(batch_size=BATCH_SIZE, prompts=prompts, model=student, tokenizer=student_tokenizer)\n",
    "\n",
    "    revised_prompts = []\n",
    "    revisions = []\n",
    "    for item, r_0 in zip(raw_data, r_0_list):\n",
    "        x, y, c = item['x'], item['y'], item['c']\n",
    "        revised_prompt = create_to_revise(x, c, r_0)\n",
    "        revised_prompts.append(revised_prompt)\n",
    "        revisions.append(y)\n",
    "\n",
    "    # 2. teacher revises (no grad)\n",
    "    with torch.no_grad():\n",
    "        revisions = teacher_generate_batch(revised_prompts, model=\"gpt-4o-mini\", system_prompt=\"You are an expert writer.\")\n",
    "    \n",
    "    print(revised_prompts[332], revisions[332])\n",
    "    return revised_prompts, revisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07ef518c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def train(model, train_loader, optimizer, writer, epoch):\n",
    "\n",
    "    total_loss = 0\n",
    "    batch_times = []\n",
    "    progress = tqdm(train_loader, desc=f\"Training Epoch {epoch}\", leave=True)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for i, batch in enumerate(progress):\n",
    "        start = time.time()\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        if torch.all(labels == -100) or torch.all(input_ids == 0):\n",
    "            print(f\"⏭️  Skipping empty batch {i}\")\n",
    "            continue\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss  # normalize loss for accumulation\n",
    "                \n",
    "        if torch.isnan(loss):\n",
    "            continue\n",
    "        # assert not math.isnan(loss.item()), f'Loss: {loss}, \\nOutputs: {outputs}'\n",
    "        loss.backward()\n",
    "    \n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        optimizer.step()\n",
    "        torch.cuda.synchronize()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()  \n",
    "        avg_loss = total_loss / (i + 1)\n",
    "\n",
    "\n",
    "        batch_time = time.time() - start\n",
    "        batch_times.append(batch_time)\n",
    "        avg_time = sum(batch_times) / len(batch_times)\n",
    "        eta = avg_time * (len(train_loader) - (i + 1))\n",
    "        eta_hr, remainder = divmod(int(eta), 3600)\n",
    "        eta_min, eta_sec = divmod(remainder, 60)\n",
    "\n",
    "        progress.set_postfix(loss=[loss.item(), avg_loss], eta=f\"{eta_hr}h {eta_min}m {eta_sec}s\")\n",
    "\n",
    "        if i % 1000 == 0 and i != 0:\n",
    "            torch.cuda.empty_cache()\n",
    "            model.save_pretrained('./latest_model')\n",
    "            with open('latest_opt.pkl', 'wb') as f:\n",
    "                pickle.dump(optimizer, f)\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    writer.add_scalar(\"Loss/train\", avg_loss, epoch * len(train_loader) + i)\n",
    "    return float(avg_loss)\n",
    "\n",
    "\n",
    "def test(model, test_loader, writer, epoch, return_generations=False):\n",
    "    total_loss = 0\n",
    "    batch_times = []\n",
    "    progress = tqdm(test_loader, desc=f\"Testing Epoch {epoch}\", leave=True)\n",
    "\n",
    "    for i, batch in enumerate(progress):\n",
    "        start = time.time()\n",
    "        \n",
    "        input_ids = batch['input_ids'].long().to(device)\n",
    "        attention_mask = batch['attention_mask'].long().to(device)\n",
    "        labels = batch['labels'].long().to(device)\n",
    "        \n",
    "        if torch.all(labels == -100) or torch.all(input_ids == 0):\n",
    "            print(f\"⏭️  Skipping empty batch {i}\")\n",
    "            continue\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        if math.isnan(loss):\n",
    "            print(\"NAN loss\")\n",
    "            continue\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        avg_loss = float(total_loss) / (i + 1)\n",
    "\n",
    "\n",
    "        batch_time = time.time() - start\n",
    "        batch_times.append(batch_time)\n",
    "        avg_time = sum(batch_times) / len(batch_times)\n",
    "        eta = avg_time * (len(test_loader) - (i + 1))\n",
    "        eta_hr, remainder = divmod(int(eta), 3600)\n",
    "        eta_min, eta_sec = divmod(remainder, 60)\n",
    "\n",
    "        progress.set_postfix(loss=[loss.item(), avg_loss], eta=f\"{eta_hr}h {eta_min}m {eta_sec}s\")\n",
    "        \n",
    "        if (i + 1) % 10 == 0:\n",
    "            model.save_pretrained('./checkpoints/latest_step')\n",
    "        if i % 1000 == 0 and i != 0:\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    writer.add_scalar(\"Loss/val\", avg_loss, epoch)\n",
    "    return float(avg_loss)\n",
    "\n",
    "\n",
    "def fine_tune(model, train_loader, test_loader, optimizer, num_epochs):\n",
    "    writer = SummaryWriter()  \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train(model, train_loader, optimizer, writer, epoch)\n",
    "        # model.save_pretrained('./citing_model')\n",
    "        val_loss = test(model, test_loader, writer, epoch)\n",
    "        print(f'Epoch: {epoch}. Train Loss: {train_loss}. Val Loss: {val_loss}.')\n",
    "        \n",
    "    # model.save_pretrained('./citing_model')\n",
    "\n",
    "    writer.close()\n",
    "    return train_loss, val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97edfec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_short_dataloaded = load_data(train_short)\n",
    "train_med_dataloaded = load_data(train_med)\n",
    "train_long_dataloaded = load_data(train_long)\n",
    "test_dataloaded = load_data(test_raw)\n",
    "\n",
    "UR_train_short_prompts = [item[0][\"content\"] for item in train_short_dataloaded]\n",
    "UR_train_med_prompts = [item[0][\"content\"] for item in train_med_dataloaded]\n",
    "UR_train_long_prompts = [item[0][\"content\"] for item in train_long_dataloaded]\n",
    "UR_test_prompts = [item[0][\"content\"] for item in test_dataloaded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "501967d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"test_prompts.pkl\", \"rb\") as f:\n",
    "#     test_prompts = pickle.load(f)\n",
    "# with open(\"test_completions.pkl\", \"rb\") as f:\n",
    "#     test_completions = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "868fcc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"short_initial_responses.json\", \"r\") as f:\n",
    "#     short_r_0_list_raw = json.load(f)\n",
    "# short_r_0_list = [ex[\"completion\"] for ex in short_r_0_list_raw]\n",
    "\n",
    "# with open(\"med_initial_responses.json\", \"r\") as f:\n",
    "#     med_r_0_list_raw = json.load(f)\n",
    "# med_r_0_list = [ex[\"completion\"] for ex in med_r_0_list_raw]\n",
    "\n",
    "# with open(\"long_initial_responses.json\", \"r\") as f:\n",
    "#     long_r_0_list_raw = json.load(f)\n",
    "# long_r_0_list = [ex[\"completion\"] for ex in long_r_0_list_raw]\n",
    "\n",
    "# with open(\"test_initial_responses.json\", \"r\") as f:\n",
    "#     test_r_0_list_raw = json.load(f)\n",
    "# test_r_0_list = [ex[\"completion\"] for ex in test_r_0_list_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11713d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_CITING(train_prompts, train_raw, r_0_list, test_prompts, test_completions, student, tokenizer, num_epochs):\n",
    "    optim = torch.optim.AdamW(filter(lambda p: p.requires_grad, student.parameters()), lr=1e-6)\n",
    "    \n",
    "    train_prompts, train_completions = get_revisions(r_0_list, train_raw)\n",
    "    print(\"\\n LEN: \", len(train_raw))\n",
    "    print(\"\\n LEN: \", len(train_prompts))\n",
    "    train_set_loaded = load_data_from_list(train_prompts, train_completions)\n",
    "    print(\"\\n LEN: \", len(train_set_loaded))\n",
    "    train_set_CL = CLDataset(train_set_loaded, tokenizer)\n",
    "    train_loader = DataLoader(train_set_CL, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    \n",
    "    # test_prompts, test_completions = get_revisions(r_0_list, train_raw)\n",
    "    test_set_loaded = load_data_from_list(test_prompts, test_completions)\n",
    "    test_set_CL = CLDataset(test_set_loaded, tokenizer)\n",
    "    test_loader = DataLoader(test_set_CL, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    \n",
    "    train_loss, val_loss = fine_tune(\n",
    "        model = student,\n",
    "        train_loader = train_loader,\n",
    "        test_loader = test_loader,\n",
    "        optimizer = optim,\n",
    "        num_epochs = num_epochs\n",
    "    )\n",
    "\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8bcab36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "student.to(device)\n",
    "print(student.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6969ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_r_0 = [item[\"completion\"] for item in test_r_0_list_raw]\n",
    "# test_x = [item[\"prompt\"] for item in test_r_0_list_raw]\n",
    "# crit = [item[\"c\"] for item in test_raw]\n",
    "\n",
    "# test_prompts = [create_to_revise(x, c, r_0) for x, c, r_0 in zip(test_x, crit, test_r_0)]\n",
    "# test_completions = [item[\"y\"] for item in test_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e154840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loss, val_loss = run_CITING(UR_train_short_prompts, train_short, short_r_0_list, test_prompts, test_completions, student, student_tokenizer, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d262e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loss, val_loss = run_CITING(UR_train_med_prompts, train_med, med_r_0_list, test_prompts, test_completions, student, student_tokenizer, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13096794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loss, val_loss = run_CITING(UR_train_long_prompts, train_long, long_r_0_list, test_prompts, test_completions, student, student_tokenizer, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f3af7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_set_loaded = load_data_from_list(test_prompts, test_completions)\n",
    "# test_set_CL = CLDataset(test_set_loaded, student_tokenizer)\n",
    "# test_loader = DataLoader(test_set_CL, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"./citing_model\", torch_dtype=torch.float16,).to(device)\n",
    "# model.eval()\n",
    "# writer = SummaryWriter() \n",
    "# val_loss = test(model, test_loader, writer, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6de9e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(raw, student, tokenizer):\n",
    "    prompts = [item[\"x\"] for item in raw]\n",
    "    outputs_list = student_generate_batch(8, prompts, student, tokenizer)\n",
    "    return outputs_list\n",
    "\n",
    "def generate_initial_responses_batched(short_raw, med_raw, long_raw, test_raw, student, tokenizer, batch_size=100) :\n",
    "    length = len(train_short)\n",
    "    test_length = len(test_raw)\n",
    "    \n",
    "    short_initial_responses = []\n",
    "    med_initial_responses = []\n",
    "    long_initial_responses = []\n",
    "    test_initial_responses = []\n",
    "    \n",
    "    for i in range(0, length, batch_size):\n",
    "        end = length if (i+batch_size > length) else i+batch_size\n",
    "        short_initial_responses.extend(generate_batch(short_raw[i:end], student, tokenizer))\n",
    "        med_initial_responses.extend(generate_batch(med_raw[i:end], student, tokenizer))\n",
    "        long_initial_responses.extend(generate_batch(long_raw[i:end], student, tokenizer))\n",
    "        \n",
    "        with open(\"short_initial_responses.json\", \"w\") as f:\n",
    "            json.dump(short_initial_responses, f, indent=4)\n",
    "        with open(\"med_initial_responses.json\", \"w\") as f:\n",
    "            json.dump(med_initial_responses, f, indent=4)\n",
    "        with open(\"long_initial_responses.json\", \"w\") as f:\n",
    "            json.dump(long_initial_responses, f, indent=4)\n",
    "        \n",
    "        if i < test_length:\n",
    "            end = test_length if (i+batch_size > test_length) else i+batch_size\n",
    "            test_initial_responses.extend(generate_batch(test_raw[i:end], student, tokenizer))\n",
    "            with open(\"test_initial_responses.json\", \"w\") as f:\n",
    "                json.dump(test_initial_responses, f, indent=4)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "61437342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [01:32<00:00,  7.12s/it]\n",
      "100%|██████████| 13/13 [01:32<00:00,  7.12s/it]\n",
      "100%|██████████| 13/13 [01:34<00:00,  7.25s/it]\n",
      "100%|██████████| 13/13 [01:36<00:00,  7.39s/it]\n",
      "100%|██████████| 13/13 [01:30<00:00,  6.97s/it]\n",
      "100%|██████████| 13/13 [01:31<00:00,  7.01s/it]\n",
      "100%|██████████| 13/13 [01:32<00:00,  7.13s/it]\n",
      "100%|██████████| 13/13 [01:35<00:00,  7.32s/it]\n",
      "100%|██████████| 13/13 [01:28<00:00,  6.77s/it]\n",
      "100%|██████████| 13/13 [01:30<00:00,  6.93s/it]\n",
      "100%|██████████| 13/13 [01:29<00:00,  6.85s/it]\n",
      "100%|██████████| 13/13 [01:34<00:00,  7.28s/it]\n",
      "100%|██████████| 13/13 [01:29<00:00,  6.85s/it]\n",
      "100%|██████████| 13/13 [01:29<00:00,  6.88s/it]\n",
      "100%|██████████| 13/13 [01:30<00:00,  6.99s/it]\n",
      "100%|██████████| 13/13 [01:35<00:00,  7.36s/it]\n",
      "100%|██████████| 13/13 [01:28<00:00,  6.83s/it]\n",
      "100%|██████████| 13/13 [01:33<00:00,  7.17s/it]\n",
      "100%|██████████| 13/13 [01:33<00:00,  7.20s/it]\n",
      "100%|██████████| 13/13 [01:37<00:00,  7.48s/it]\n",
      "100%|██████████| 13/13 [01:31<00:00,  7.04s/it]\n",
      "100%|██████████| 13/13 [01:32<00:00,  7.14s/it]\n",
      "100%|██████████| 13/13 [01:31<00:00,  7.07s/it]\n",
      "100%|██████████| 13/13 [01:31<00:00,  7.04s/it]\n",
      "100%|██████████| 13/13 [01:32<00:00,  7.15s/it]\n",
      "100%|██████████| 13/13 [01:33<00:00,  7.22s/it]\n",
      "100%|██████████| 13/13 [01:32<00:00,  7.13s/it]\n",
      "100%|██████████| 13/13 [01:31<00:00,  7.07s/it]\n",
      "100%|██████████| 13/13 [01:33<00:00,  7.22s/it]\n",
      "100%|██████████| 13/13 [01:30<00:00,  6.98s/it]\n",
      "100%|██████████| 13/13 [01:32<00:00,  7.10s/it]\n",
      "100%|██████████| 13/13 [01:31<00:00,  7.05s/it]\n",
      "100%|██████████| 13/13 [01:31<00:00,  7.05s/it]\n",
      "100%|██████████| 13/13 [01:32<00:00,  7.09s/it]\n",
      "100%|██████████| 13/13 [01:32<00:00,  7.13s/it]\n",
      "100%|██████████| 13/13 [01:31<00:00,  7.02s/it]\n",
      "100%|██████████| 13/13 [01:32<00:00,  7.13s/it]\n",
      "100%|██████████| 13/13 [01:33<00:00,  7.17s/it]\n",
      "100%|██████████| 13/13 [01:31<00:00,  7.06s/it]\n",
      "100%|██████████| 13/13 [01:32<00:00,  7.10s/it]\n",
      "100%|██████████| 13/13 [01:34<00:00,  7.27s/it]\n",
      "100%|██████████| 13/13 [01:31<00:00,  7.02s/it]\n",
      "100%|██████████| 13/13 [01:32<00:00,  7.13s/it]\n",
      "100%|██████████| 13/13 [01:36<00:00,  7.44s/it]\n",
      "100%|██████████| 13/13 [01:32<00:00,  7.15s/it]\n",
      "100%|██████████| 13/13 [01:34<00:00,  7.26s/it]\n",
      "100%|██████████| 13/13 [01:36<00:00,  7.46s/it]\n",
      "100%|██████████| 13/13 [01:33<00:00,  7.18s/it]\n",
      "100%|██████████| 13/13 [01:31<00:00,  7.00s/it]\n",
      "100%|██████████| 13/13 [01:32<00:00,  7.10s/it]\n",
      "100%|██████████| 13/13 [01:28<00:00,  6.83s/it]\n",
      "100%|██████████| 13/13 [01:30<00:00,  6.94s/it]\n",
      "100%|██████████| 13/13 [01:33<00:00,  7.23s/it]\n",
      "100%|██████████| 13/13 [01:29<00:00,  6.86s/it]\n",
      "100%|██████████| 13/13 [01:29<00:00,  6.86s/it]\n",
      "100%|██████████| 13/13 [01:30<00:00,  6.95s/it]\n",
      "100%|██████████| 13/13 [01:32<00:00,  7.11s/it]\n",
      "100%|██████████| 13/13 [01:34<00:00,  7.25s/it]\n",
      "100%|██████████| 13/13 [01:35<00:00,  7.38s/it]\n",
      "100%|██████████| 13/13 [01:33<00:00,  7.16s/it]\n",
      "100%|██████████| 13/13 [01:30<00:00,  6.93s/it]\n",
      "100%|██████████| 13/13 [01:31<00:00,  7.06s/it]\n",
      "100%|██████████| 13/13 [01:29<00:00,  6.89s/it]\n",
      "100%|██████████| 13/13 [01:32<00:00,  7.14s/it]\n",
      "100%|██████████| 13/13 [01:35<00:00,  7.38s/it]\n",
      "100%|██████████| 13/13 [01:29<00:00,  6.86s/it]\n",
      "100%|██████████| 13/13 [01:30<00:00,  6.94s/it]\n",
      "100%|██████████| 13/13 [01:33<00:00,  7.19s/it]\n",
      "100%|██████████| 13/13 [01:28<00:00,  6.80s/it]\n",
      "100%|██████████| 13/13 [01:29<00:00,  6.87s/it]\n",
      "100%|██████████| 13/13 [01:33<00:00,  7.20s/it]\n",
      "100%|██████████| 13/13 [01:29<00:00,  6.89s/it]\n",
      "100%|██████████| 13/13 [01:30<00:00,  6.95s/it]\n",
      "100%|██████████| 13/13 [01:34<00:00,  7.26s/it]\n",
      "100%|██████████| 13/13 [01:31<00:00,  7.07s/it]\n",
      "100%|██████████| 13/13 [01:32<00:00,  7.13s/it]\n",
      "100%|██████████| 13/13 [01:34<00:00,  7.28s/it]\n",
      "100%|██████████| 13/13 [01:29<00:00,  6.87s/it]\n",
      "100%|██████████| 13/13 [01:30<00:00,  6.95s/it]\n",
      "100%|██████████| 13/13 [01:34<00:00,  7.26s/it]\n",
      "100%|██████████| 13/13 [01:29<00:00,  6.87s/it]\n",
      "100%|██████████| 13/13 [01:30<00:00,  6.96s/it]\n",
      "100%|██████████| 13/13 [01:34<00:00,  7.28s/it]\n",
      "100%|██████████| 13/13 [01:32<00:00,  7.13s/it]\n",
      "100%|██████████| 13/13 [01:33<00:00,  7.20s/it]\n",
      "100%|██████████| 13/13 [01:37<00:00,  7.46s/it]\n",
      "100%|██████████| 13/13 [01:32<00:00,  7.12s/it]\n",
      "100%|██████████| 13/13 [01:34<00:00,  7.28s/it]\n",
      "100%|██████████| 13/13 [01:39<00:00,  7.63s/it]\n",
      "100%|██████████| 13/13 [01:34<00:00,  7.29s/it]\n",
      "100%|██████████| 13/13 [01:35<00:00,  7.32s/it]\n",
      "100%|██████████| 13/13 [01:40<00:00,  7.70s/it]\n",
      "100%|██████████| 13/13 [01:33<00:00,  7.21s/it]\n",
      "100%|██████████| 13/13 [01:34<00:00,  7.29s/it]\n",
      "100%|██████████| 13/13 [01:39<00:00,  7.68s/it]\n",
      "100%|██████████| 13/13 [01:33<00:00,  7.16s/it]\n",
      "100%|██████████| 13/13 [01:34<00:00,  7.28s/it]\n",
      "100%|██████████| 13/13 [01:40<00:00,  7.69s/it]\n",
      "100%|██████████| 13/13 [01:30<00:00,  6.98s/it]\n",
      "100%|██████████| 13/13 [01:31<00:00,  7.05s/it]\n",
      "100%|██████████| 13/13 [01:37<00:00,  7.49s/it]\n",
      "100%|██████████| 13/13 [01:28<00:00,  6.81s/it]\n",
      "100%|██████████| 13/13 [01:31<00:00,  7.06s/it]\n",
      "100%|██████████| 13/13 [01:37<00:00,  7.51s/it]\n",
      "100%|██████████| 5/5 [00:34<00:00,  6.81s/it]\n",
      "100%|██████████| 5/5 [00:35<00:00,  7.16s/it]\n",
      "100%|██████████| 5/5 [00:37<00:00,  7.56s/it]\n"
     ]
    }
   ],
   "source": [
    "generate_initial_responses_batched(train_short, train_med, train_long, test_raw, student, student_tokenizer, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
